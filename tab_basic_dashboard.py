# íŒŒì¼ ì´ë¦„: tab_basic_dashboard.py (expander ì¶”ê°€ ì™„ë£Œëœ ì „ì²´ ì½”ë“œ)

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px

def render(df: pd.DataFrame, data_type: str):
    st.header("ğŸ“Š ë°ì´í„° ê¸°ë³¸ ë™í–¥")

    # 1. í˜„ì¬ ëª¨ë“œê°€ 'ë¶„ì„ ëª¨ë“œ'ì¼ ë•Œë§Œ ëŒ€ì‹œë³´ë“œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
    if data_type == 'analysis':
        st.info("í˜„ì¬ ì—…ë¡œë“œëœ ë°ì´í„°ì˜ ì „ì²´ì ì¸ í†µê³„ì™€ ë¶„í¬ë¥¼ ìš”ì•½í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        st.markdown("---")

        # --- 1. í•œëˆˆì— ë³´ëŠ” í•µì‹¬ ìš”ì•½ ---
        st.subheader("ğŸ”¢ í•œëˆˆì— ë³´ëŠ” í•µì‹¬ ìš”ì•½")

        # ê° ì»¬ëŸ¼ì˜ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ë©° ì•ˆì „í•˜ê²Œ ê³„ì‚°
        total_papers = len(df)
        avg_citations = df.get('cited_by_count', pd.Series(dtype='float')).mean()

        if 'All_Authors' in df.columns:
            total_authors = df['All_Authors'].dropna().str.split(';').explode().str.strip().nunique()
        else: total_authors = "N/A"

        unique_first_authors = df.get('First_Author_Name', pd.Series(dtype='str')).nunique()

        if 'Corresponding_Author_Names' in df.columns:
            unique_corr_authors = df['Corresponding_Author_Names'].dropna().str.split(';').explode().str.strip().nunique()
        else: unique_corr_authors = "N/A"

        if 'All_Institutions' in df.columns:
            total_institutions = df['All_Institutions'].dropna().str.split(';').explode().str.strip().nunique()
        else: total_institutions = "N/A"

        unique_first_inst = df.get('First_Author_Institution', pd.Series(dtype='str')).nunique()

        if 'Corresponding_Institution_Names' in df.columns:
            unique_corr_inst = df['Corresponding_Institution_Names'].dropna().str.split(';').explode().str.strip().nunique()
        else: unique_corr_inst = "N/A"

        # ìš”ì•½ ì •ë³´ íƒ­ìœ¼ë¡œ í‘œì‹œ
        tab1, tab2, tab3 = st.tabs(["ì¢…í•© í˜„í™©", "ğŸ‘¤ ì—°êµ¬ì í˜„í™©", "ğŸ¢ ì—°êµ¬ê¸°ê´€ í˜„í™©"])
        with tab1:
            col1, col2 = st.columns(2)
            col1.metric("ì´ ë…¼ë¬¸ ìˆ˜", f"{total_papers:,}")
            col2.metric("í‰ê·  í”¼ì¸ìš© ìˆ˜", f"{avg_citations:.1f}" if pd.notna(avg_citations) else "N/A")
        with tab2:
            col1, col2, col3 = st.columns(3)
            col1.metric("ì´ ì €ì ìˆ˜(ì „ì²´)", f"{total_authors:,}" if isinstance(total_authors, int) else total_authors)
            col2.metric("ì£¼ì €ì ìˆ˜(ê³ ìœ )", f"{unique_first_authors:,}")
            col3.metric("êµì‹ ì €ì ìˆ˜(ê³ ìœ )", f"{unique_corr_authors:,}" if isinstance(unique_corr_authors, int) else unique_corr_authors)
        with tab3:
            col1, col2, col3 = st.columns(3)
            col1.metric("ì´ ê¸°ê´€ ìˆ˜(ì „ì²´)", f"{total_institutions:,}" if isinstance(total_institutions, int) else total_institutions)
            col2.metric("ì£¼ì €ì ì†Œì†ê¸°ê´€ ìˆ˜", f"{unique_first_inst:,}")
            col3.metric("êµì‹ ì €ì ì†Œì†ê¸°ê´€ ìˆ˜", f"{unique_corr_inst:,}" if isinstance(unique_corr_inst, int) else unique_corr_inst)
        st.markdown("---")

        # --- 2. ê²°ì¸¡ì¹˜ í˜„í™© ---
        with st.expander("ë¶„ì„ ë°ì´í„° ìƒì„¸ ì •ë³´ ë³´ê¸° (ê²°ì¸¡ì¹˜ í˜„í™©)"):
            total_rows = len(df)
            key_fields = {
                'Corresponding_Author_Names': 'êµì‹ ì €ì', 'First_Author_Country': 'ì£¼ì €ì êµ­ê°€', 'fwci': 'FWCI ì§€ìˆ˜'
            }
            summary_data = []
            for field, name in key_fields.items():
                if field in df.columns:
                    valid_count = df[field].notna().sum()
                    missing_rate = (1 - valid_count / total_rows) * 100 if total_rows > 0 else 0
                    summary_data.append({"í•­ëª©": name, "ë°ì´í„° ë³´ìœ ìœ¨": f"{100-missing_rate:.1f}%", "ê²°ì¸¡ë¥ ": f"{missing_rate:.1f}%"})

            if summary_data:
                st.dataframe(pd.DataFrame(summary_data), hide_index=True, use_container_width=True)
            st.info("**FWCI (Field-Weighted Citation Impact):** ì£¼ì œ ë¶„ì•¼, ë°œí–‰ ì—°ë„, ë¬¸ì„œ ìœ í˜•ì´ ë¹„ìŠ·í•œ ë‹¤ë¥¸ ë…¼ë¬¸ë“¤ê³¼ ë¹„êµí•˜ì—¬, í•´ë‹¹ ë…¼ë¬¸ì´ ë°›ì€ ì¸ìš© ìˆ˜ë¥¼ ì •ê·œí™”í•œ 'ì§ˆì  ì˜í–¥ë ¥' ì§€í‘œì…ë‹ˆë‹¤. (FWCI > 1 ì´ë©´ ì„¸ê³„ í‰ê·  ì´ìƒ)")
        st.markdown("---")

        # --- 3. ê¸°ë³¸ ë™í–¥ ì‹œê°í™” ---
        st.subheader("ğŸ“ˆ ì£¼ìš” í•­ëª©ë³„ ë¶„í¬")
        col_graph1, col_graph2 = st.columns(2)

        with col_graph1:
            st.markdown("###### ì—°ë„ë³„ ë…¼ë¬¸ ë°œí–‰ ë™í–¥")
            if 'publication_year' in df.columns and df['publication_year'].notna().any():
                yearly_counts = df['publication_year'].dropna().astype(int).value_counts().sort_index()
                fig_yearly = px.bar(yearly_counts, x=yearly_counts.index, y=yearly_counts.values, labels={'x': 'ë°œí–‰ ì—°ë„', 'y': 'ë…¼ë¬¸ ìˆ˜'})
                fig_yearly.update_traces(marker_color='#418cdc' )
                st.plotly_chart(fig_yearly, use_container_width=True)

                with st.expander("ë°ì´í„° ë³´ê¸°"):
                    st.dataframe(yearly_counts)
            else:
                st.warning("ë°œí–‰ ì—°ë„ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            st.markdown("###### êµ­ê°€ë³„ ì—°êµ¬ ë™í–¥ (ì£¼ì €ì êµ­ê°€ ê¸°ì¤€ Top 15)")
            if 'First_Author_Country' in df.columns and df['First_Author_Country'].notna().any():
                country_series = df['First_Author_Country'].dropna().str.split(';').explode().str.strip()
                country_counts = country_series.value_counts().nlargest(15)
                fig_country = px.bar(country_counts, y=country_counts.index, x=country_counts.values, orientation='h', labels={'y': 'êµ­ê°€', 'x': 'ë…¼ë¬¸ ìˆ˜'})
                fig_country.update_traces(marker_color='#418cdc')
                fig_country.update_layout(yaxis={'categoryorder':'total ascending'})
                st.plotly_chart(fig_country, use_container_width=True)

                with st.expander("ë°ì´í„° ë³´ê¸°"):
                    st.dataframe(country_counts)
            else:
                st.warning("ì£¼ì €ì êµ­ê°€ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        with col_graph2:
            st.markdown("###### í•µì‹¬ ì—°êµ¬ ê¸°ê´€ (ë…¼ë¬¸ ìˆ˜ ê¸°ì¤€ Top 15)")
            if 'All_Institutions' in df.columns and df['All_Institutions'].notna().any():
                institution_series = df['All_Institutions'].dropna().str.split(';').explode().str.strip()
                non_blank_institutions = institution_series[institution_series != '']
                institution_counts = non_blank_institutions.value_counts().nlargest(15)
                fig_inst = px.bar(institution_counts, y=institution_counts.index, x=institution_counts.values, orientation='h', labels={'y': 'ì—°êµ¬ ê¸°ê´€', 'x': 'ë…¼ë¬¸ ìˆ˜'})
                fig_inst.update_layout(yaxis={'categoryorder':'total ascending'})
                fig_inst.update_traces(marker_color='#418cdc')

                st.plotly_chart(fig_inst, use_container_width=True)

                with st.expander("ë°ì´í„° ë³´ê¸°"):
                    st.dataframe(institution_counts)
            else:
                st.warning("ì—°êµ¬ ê¸°ê´€ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            st.markdown("###### ì£¼ìš” ì—°êµ¬ í† í”½ (Primary Topic ê¸°ì¤€ Top 15)")
            if 'Primary_Topic(Score)' in df.columns and df['Primary_Topic(Score)'].notna().any():
                df['Primary_Topic_Clean'] = df['Primary_Topic(Score)'].str.split('(').str[0].str.strip()
                topic_counts = df['Primary_Topic_Clean'].value_counts().nlargest(15)
                fig_topic = px.bar(topic_counts, y=topic_counts.index, x=topic_counts.values, orientation='h', labels={'y': 'ì£¼ìš” í† í”½', 'x': 'ë¹ˆë„ ìˆ˜'})
                fig_topic.update_layout(yaxis={'categoryorder':'total ascending'})
                fig_topic.update_traces(marker_color='#418cdc')
                st.plotly_chart(fig_topic, use_container_width=True)

                with st.expander("ë°ì´í„° ë³´ê¸°"):
                    st.dataframe(topic_counts)
            else:
                st.warning("ì—°êµ¬ í† í”½ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 2. í˜„ì¬ ëª¨ë“œê°€ 'ë¶„ì„ ëª¨ë“œ'ê°€ ì•„ë‹ ê²½ìš° íŒŒì¼ ì—…ë¡œë”ë¥¼ í‘œì‹œ
    else:
        st.info("ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ë ¤ë©´ ì•„ë˜ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

        uploaded_file = st.file_uploader(
            "ë¶„ì„í•  ì—‘ì…€(csv) íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.",
            type=['csv', 'xlsx'],
            key="dashboard_uploader"
        )

        if uploaded_file is not None:
            # íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´, main.pyì— ì²˜ë¦¬í•  'ì•¡ì…˜'ì„ ë“±ë¡í•©ë‹ˆë‹¤.
            try:
                uploaded_df = pd.read_csv(uploaded_file) if uploaded_file.name.endswith('.csv') else pd.read_excel(uploaded_file)
                # 'ì‘ì—… ì§€ì‹œì„œ' ë“±ë¡
                st.session_state.pending_action = ('UPLOAD_ACTION', uploaded_df)
                # main.pyê°€ ì•¡ì…˜ì„ ì²˜ë¦¬í•˜ë„ë¡ ì¦‰ì‹œ ì¬ë¡œë”© ìš”ì²­
                st.rerun()
            except Exception as e:
                st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")