# íŒŒì¼ ì´ë¦„: tab_search.py (ì „ëµ ì ìš© í›„ ìˆ˜ì •ëœ ë²„ì „)

import streamlit as st
import datetime
import os
import pandas as pd
import io
from modules import url_builder, data_fetcher, data_processor

# ê¸°ë³¸ ê²€ìƒ‰ì–´ ì„¤ì •
DEFAULT_OR_KEYWORDS = (
    "MRAM, PRAM, RRAM, FeRAM, OxRAM, CBRAM, "
    "\"Resistive Random-Access Memory\", \"Magnetoresistive Random-Access Memory\", "
    "\"Ferroelectric Random-Access Memory\", \"non-volatile memory\", \"nonvolatile memory\", "
    "\"emerging memory\", \"next-generation memory\", \"storage class memory\", "
    "\"novel memory\", \"advanced memory\", memristor, memristive"
)

def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜"""
    if 'search_step' not in st.session_state:
        st.session_state.search_step = "start"

def render(): # âœ¨ ì¸ìëŠ” ë°›ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """ë…¼ë¬¸ ê²€ìƒ‰, ìˆ˜ì§‘, ì •ì œ ì›Œí¬í”Œë¡œìš°ë¥¼ ë‹´ë‹¹í•˜ëŠ” UIì™€ ë¡œì§ì„ ë Œë”ë§í•©ë‹ˆë‹¤."""

    initialize_session_state()

    # ==============================================================================
    # 1. UI (ì…ë ¥ ì„¹ì…˜)
    # ==============================================================================

    if st.session_state.search_step in ["start", "done"]:
        with st.container(border=True):
            st.header("1. ê²€ìƒ‰ ì¡°ê±´ ì„¤ì •")

            # --- í•„ìˆ˜ ì…ë ¥: ì´ë©”ì¼ ì£¼ì†Œ (ê°•ì¡°ëœ ì•ˆë‚´ ë©”ì‹œì§€ì™€ í•¨ê»˜) ---
            st.info("â„¹ï¸ **ë°˜ë“œì‹œ ë³¸ì¸ì˜ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì…ë ¥í•´ì•¼ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.** (OpenAlex API ì •ì±…)")
            email = st.text_input(
                label="API ì‚¬ìš© ì´ë©”ì¼ ì£¼ì†Œ (í•„ìˆ˜)",
                placeholder="your.email@company.com",
                value="",
                key="api_email_input"
            )

            col1, col2 = st.columns(2)

            with col1:
                or_keywords_input = st.text_area("OR í‚¤ì›Œë“œ (í•˜ë‚˜ë¼ë„ í¬í•¨)", value=DEFAULT_OR_KEYWORDS, height=250, key="or_keywords")
            with col2:
                and_keywords_input = st.text_area("AND í‚¤ì›Œë“œ (ëª¨ë‘ í¬í•¨)", "neuromorphic", height=100, key="and_keywords")

                st.markdown("---")
                st.subheader("2. ê²€ìƒ‰ ê¸°ê°„")
                current_year = datetime.datetime.now().year

                sub_col1, sub_col2 = st.columns(2)
                with sub_col1:
                    start_year = st.number_input("ì‹œì‘ ì—°ë„", min_value=1980, max_value=current_year + 1, value=2015, key='start_year')
                with sub_col2:
                    end_year = st.number_input("ì¢…ë£Œ ì—°ë„", min_value=1980, max_value=current_year + 1, value=current_year, key='end_year')

            if start_year > end_year:
                st.error("ì˜¤ë¥˜: ì‹œì‘ ì—°ë„ëŠ” ì¢…ë£Œ ì—°ë„ë³´ë‹¤ í´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()

            with st.expander("ìƒì„¸ ê²€ìƒ‰ ì¡°ê±´ í¼ì¹˜ê¸°"):
                type_options = {
                    'í•™ìˆ  ë…¼ë¬¸ (Article)': 'article', 'í•™íšŒ ë°œí‘œ ìë£Œ (Conference Paper)': 'conference',
                    'ë„ì„œ ì±•í„° (Book Chapter)': 'book-chapter', 'ë¦¬ë·° (Review)': 'review', 'í•™ìœ„ ë…¼ë¬¸ (Dissertation)': 'dissertation'
                }
                selected_includes = st.multiselect("í¬í•¨í•  ë¬¸ì„œ ìœ í˜•", options=list(type_options.keys()), default=['í•™ìˆ  ë…¼ë¬¸ (Article)', 'í•™íšŒ ë°œí‘œ ìë£Œ (Conference Paper)'], key="doc_types")

                search_mode_option = st.radio("ê²€ìƒ‰ ë²”ìœ„", ('ë„“ê²Œ ê²€ìƒ‰ (í¬ê´„ì )', 'ì •í™•í•˜ê²Œ ê²€ìƒ‰ (í•µì‹¬ì )'), horizontal=True, key="search_mode")

        # --- ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ë²„íŠ¼ ---
        if st.button("ë…¼ë¬¸ ë°ì´í„° ìˆ˜ì§‘ ë° ì •ì œ ì‹œì‘", type="primary", use_container_width=True):
            if not email or "@" not in email:
                st.error("í•„ìˆ˜ í•­ëª©ì¸ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì˜¬ë°”ë¥´ê²Œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                st.session_state.search_step = "collecting"
                st.session_state.ui_inputs = {
                    "email": email,
                    "or_keywords_input": or_keywords_input,
                    "and_keywords_input": and_keywords_input,
                    "start_year": start_year,
                    "end_year": end_year,
                    "include_types_values": [type_options[key] for key in selected_includes],
                    "search_mode": 'broad' if 'ë„“ê²Œ' in search_mode_option else 'precise'
                }
                st.rerun()

    # ==============================================================================
    # 2. ë°ì´í„° ìˆ˜ì§‘ ë‹¨ê³„ (ë°±ê·¸ë¼ìš´ë“œ ë¡œì§)
    # ==============================================================================
    if st.session_state.search_step == "collecting":
        with st.spinner("1/2 - URL ìƒì„± ë° ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
            inputs = st.session_state.ui_inputs.copy()
            search_mode = inputs.pop('search_mode')
            params = url_builder.prepare_params(**inputs)
            if search_mode == 'broad':
                api_url = url_builder.create_broad_query(**params)
            else:
                api_url = url_builder.create_precise_query(**params)
            st.code(f"API URL: {api_url}", language="text")
            DATA_DIR = "data"
            if not os.path.exists(DATA_DIR): os.makedirs(DATA_DIR)
            output_filepath = os.path.join(DATA_DIR, "collected_data.jsonl")
            data_fetcher.fetch_and_save_incrementally(api_url, output_filepath)
            st.session_state['data_filepath'] = output_filepath
            st.session_state.search_step = "processing"
            st.rerun()

    # ==============================================================================
    # 3. ë°ì´í„° ì •ì œ ë‹¨ê³„ (ë°±ê·¸ë¼ìš´ë“œ ë¡œì§)
    # ==============================================================================
    if st.session_state.search_step == "processing":
        filepath = st.session_state['data_filepath']
        with st.spinner(f"2/2 - '{os.path.basename(filepath)}' íŒŒì¼ ì •ì œ ë° ë¶„ì„ ì¤€ë¹„ ì¤‘..."):
            final_df = data_processor.process_and_refine_data(filepath)

            # âœ¨âœ¨âœ¨ --- ì—¬ê¸°ê°€ ìœ ì¼í•œ í•µì‹¬ ìˆ˜ì • ì§€ì  --- âœ¨âœ¨âœ¨
            # 1. ìƒíƒœë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ëŠ” ëŒ€ì‹ , main.pyì— ì²˜ë¦¬í•  'ì•¡ì…˜'ì„ ë“±ë¡í•©ë‹ˆë‹¤.
            st.session_state.pending_action = ('SEARCH_ACTION', final_df)

            # 2. ì´ íƒ­ì—ì„œ ì‚¬ìš©í–ˆë˜ ì„ì‹œ ë°ì´í„°(final_df)ëŠ” ì´ì œ ì„¸ì…˜ì— ì €ì¥í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.
            #    (ì£¼ì„ ì²˜ë¦¬ ë˜ëŠ” ì‚­ì œ)
            # st.session_state['final_df'] = final_df

            # 3. ì´ íƒ­ì˜ ìƒíƒœë¥¼ 'ì™„ë£Œ'ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
            st.session_state.search_step = "done"

            # 4. main.pyê°€ ì•¡ì…˜ì„ ì²˜ë¦¬í•˜ë„ë¡ ì¦‰ì‹œ ì¬ë¡œë”©(rerun)ì„ ìš”ì²­í•©ë‹ˆë‹¤.
            st.rerun()
            # âœ¨âœ¨âœ¨ --- ìˆ˜ì • ë --- âœ¨âœ¨âœ¨

    # ==============================================================================
    # 4. ìµœì¢… ê²°ê³¼ í‘œì‹œ ë° ë‹¤ìš´ë¡œë“œ/ì´ˆê¸°í™”
    # ==============================================================================
    if st.session_state.search_step == "done":
        st.subheader("âœ… ìˆ˜ì§‘ ë° ì •ì œ ì™„ë£Œ")

        # ì´ì œ ë°ì´í„°ëŠ” ì¤‘ì•™ ì €ì¥ì†Œì¸ st.session_state.data ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        final_df = st.session_state.get('data', pd.DataFrame())

        if not final_df.empty and st.session_state.get('data_type') == 'search':
            st.info(f"ì´ {len(final_df)}ê°œì˜ ë…¼ë¬¸ ë°ì´í„°ê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤. í˜„ì¬ 'ê²€ìƒ‰ ëª¨ë“œ'ê°€ í™œì„±í™” ë˜ì—ˆìŠµë‹ˆë‹¤.")
            with st.expander("ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
                st.dataframe(final_df)

            @st.cache_data
            def convert_df_to_excel(df):
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    df.to_excel(writer, index=False, sheet_name='Sheet1')
                return output.getvalue()

            excel_data = convert_df_to_excel(final_df)
            st.download_button(label="ğŸ“¥ ì •ì œëœ ë°ì´í„°(ì—‘ì…€) ë‹¤ìš´ë¡œë“œ", data=excel_data, file_name="refined_paper_data.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)
        else:
            # ì´ ê²½ìš°ëŠ” ë‹¤ë¥¸ íƒ­ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ 'ë¶„ì„ ëª¨ë“œ'ë¡œ ì „í™˜ëœ ìƒíƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            st.info("ìƒˆë¡œìš´ ê²€ìƒ‰ì„ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

        if st.button("ìƒˆ ê²€ìƒ‰ ì‹œì‘í•˜ê¸°", type="secondary", use_container_width=True):
            # ì´ íƒ­ ë‚´ë¶€ì˜ ìƒíƒœë§Œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
            keys_to_delete = ['search_step', 'ui_inputs', 'data_filepath', 'api_email_input', 'or_keywords', 'and_keywords', 'start_year', 'end_year', 'doc_types', 'search_mode']
            for key in keys_to_delete:
                if key in st.session_state:
                    del st.session_state[key]

            # íŒŒì¼ ì‚­ì œ ë¡œì§ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
            filepath = os.path.join("data", "collected_data.jsonl")
            if os.path.exists(filepath):
                os.remove(filepath)

            st.rerun()