# íŒŒì¼ ì´ë¦„: tab_deep_dashboard.py (ì „ëµ ì ìš© í›„ ìµœì¢… ìˆ˜ì • ë²„ì „)

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from wordcloud import WordCloud
import re

# ==============================================================================
# ë°ì´í„° í´ë¦¬ë‹ì„ ìœ„í•œ ì „ìš© í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ)
# ==============================================================================
def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    missing_values = ['nan', 'None', 'none', 'null', '']
    for col in df.select_dtypes(include='object').columns:
        df[col] = df[col].str.strip()
        df[col].replace(missing_values, np.nan, inplace=True)
    numeric_cols = ['publication_year', 'cited_by_count', 'fwci', 'Citation_Percentile']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    return df

# ==============================================================================
# âœ¨ ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜ (ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì— ë§ê²Œ ìˆ˜ì •)
# ==============================================================================
def render(df: pd.DataFrame, data_type: str):
    st.header("ğŸ”¬ í‚¤ì›Œë“œ ê¸°ë°˜ ë™í–¥ ë¶„ì„")
    st.info("í•µì‹¬ ê¸°ìˆ  í‚¤ì›Œë“œì˜ ë¶€ìƒê³¼ ì‡ í‡´, ê·¸ë¦¬ê³  ì´ë¥¼ ì£¼ë„í•˜ëŠ” ê²½ìŸ êµ¬ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
    st.markdown("---")

    # âœ¨ 1. í˜„ì¬ ëª¨ë“œê°€ 'ë¶„ì„ ëª¨ë“œ'ì¼ ë•Œë§Œ ëŒ€ì‹œë³´ë“œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
    if data_type == 'analysis':

        # âœ¨ 2. ì „ë‹¬ë°›ì€ ì›ë³¸ ë°ì´í„°ë¥¼ ì´ íƒ­ì— ë§ê²Œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
        df = clean_dataframe(df.copy())

        st.success(f"**ì´ {len(df):,}ê±´**ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        st.markdown("---")

        keyword_col = 'Keywords(Scores)'
        if keyword_col not in df.columns:
            st.error(f"'{keyword_col}' ì»¬ëŸ¼ì´ ì—†ì–´ ì‹¬ì¸µ ë™í–¥ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        keywords_series = df.dropna(subset=[keyword_col])[keyword_col]
        all_keywords_raw = keywords_series.str.split(';').explode()
        pure_keywords = all_keywords_raw.str.split('(').str[0].str.strip()
        pure_keywords = pure_keywords[pure_keywords[pure_keywords != ''].notna()]

        if pure_keywords.empty:
            st.warning("ë¶„ì„í•  ìœ íš¨í•œ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        keyword_counts = pure_keywords.value_counts()

        # --- âœ¨ ì—¬ê¸°ì„œë¶€í„° ê¸°ì¡´ì˜ ëª¨ë“  í›Œë¥­í•œ í‚¤ì›Œë“œ ë¶„ì„ ë¡œì§ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤. ---

        # --- 1ë‹¨ê³„: ê¸€ë¡œë²Œ í•µì‹¬ í‚¤ì›Œë“œ ë¶„ì„ ---
        st.subheader("1. ê¸€ë¡œë²Œ í•µì‹¬ í‚¤ì›Œë“œ ë¶„ì„")
        # ... (ì´í•˜ ëª¨ë“  ë¶„ì„ ë° ì‹œê°í™” ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼) ...
        st.markdown("##### **1-1. ì „ì²´ í‚¤ì›Œë“œ ë¹ˆë„**")
        col1, col2 = st.columns([1, 1])
        with col1:
            top_20_keywords = keyword_counts.nlargest(20)
            fig_bar = px.bar(top_20_keywords, x=top_20_keywords.values, y=top_20_keywords.index, orientation='h', labels={'x': 'ë¹ˆë„ìˆ˜', 'y': 'í‚¤ì›Œë“œ'}, height=500)
            fig_bar.update_layout(yaxis={'categoryorder': 'total ascending'})
            st.plotly_chart(fig_bar, use_container_width=True)
            with st.expander("ë°ì´í„° í…Œì´ë¸” ë³´ê¸°"):
                st.dataframe(top_20_keywords.reset_index(name='ë¹ˆë„ìˆ˜').rename(columns={'index': 'í‚¤ì›Œë“œ'}), use_container_width=True)
        with col2:
            wordcloud_data = keyword_counts.to_dict()
            wc = WordCloud(width=200, height=200, scale=15, background_color='white', colormap='viridis', max_words=200, relative_scaling=0.3).generate_from_frequencies(wordcloud_data)
            st.image(wc.to_array())
        st.markdown("---")
        st.markdown("##### **1-2. ì „ì²´ í‚¤ì›Œë“œ ì—°ë„ë³„ íŠ¸ë Œë“œ**")
        # ... (ì´í•˜ ëª¨ë“  ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼í•˜ë¯€ë¡œ ì „ì²´ ì½”ë“œë¥¼ ë³´ë ¤ë©´ ìŠ¤í¬ë¡¤ì„ ë‚´ë ¤ì£¼ì„¸ìš”) ...


    # âœ¨ 3. 'ë¶„ì„ ëª¨ë“œ'ê°€ ì•„ë‹ ê²½ìš°, ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
    else:
        st.info("ì´ ëŒ€ì‹œë³´ë“œëŠ” 'ë¶„ì„ ëª¨ë“œ'ì—ì„œë§Œ í™œì„±í™”ë©ë‹ˆë‹¤. 'ê¸°ë³¸ ë™í–¥ ë¶„ì„' íƒ­ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# --- ì•„ë˜ëŠ” if data_type == 'analysis' ë¸”ë¡ ì•ˆì— ë“¤ì–´ê°€ëŠ” ì „ì²´ ë¶„ì„ ì½”ë“œì…ë‹ˆë‹¤. ---
# (ìœ„ ì½”ë“œì—ì„œ ìƒëµëœ ë¶€ë¶„ì„ í¬í•¨í•œ ì „ì²´ ì½”ë“œ)
def render(df: pd.DataFrame, data_type: str):
    st.header("ğŸ”¬ í‚¤ì›Œë“œ ê¸°ë°˜ ë™í–¥ ë¶„ì„")
    st.info("í•µì‹¬ ê¸°ìˆ  í‚¤ì›Œë“œì˜ ë¶€ìƒê³¼ ì‡ í‡´, ê·¸ë¦¬ê³  ì´ë¥¼ ì£¼ë„í•˜ëŠ” ê²½ìŸ êµ¬ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
    st.markdown("---")

    if data_type == 'analysis':
        df = clean_dataframe(df.copy())

        st.success(f"**ì´ {len(df):,}ê±´**ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        st.markdown("---")

        keyword_col = 'Keywords(Scores)'
        if keyword_col not in df.columns:
            st.error(f"'{keyword_col}' ì»¬ëŸ¼ì´ ì—†ì–´ ì‹¬ì¸µ ë™í–¥ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        keywords_series = df.dropna(subset=[keyword_col])[keyword_col]
        all_keywords_raw = keywords_series.str.split(';').explode()
        pure_keywords = all_keywords_raw.str.split('(').str[0].str.strip()
        pure_keywords = pure_keywords[pure_keywords[pure_keywords != ''].notna()]

        if pure_keywords.empty:
            st.warning("ë¶„ì„í•  ìœ íš¨í•œ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        keyword_counts = pure_keywords.value_counts()

        st.subheader("1. ê¸€ë¡œë²Œ í•µì‹¬ í‚¤ì›Œë“œ ë¶„ì„")
        st.markdown("##### **1-1. ì „ì²´ í‚¤ì›Œë“œ ë¹ˆë„**")
        col1, col2 = st.columns([1, 1])
        with col1:
            top_20_keywords = keyword_counts.nlargest(20)
            fig_bar = px.bar(top_20_keywords, x=top_20_keywords.values, y=top_20_keywords.index, orientation='h', labels={'x': 'ë¹ˆë„ìˆ˜', 'y': 'í‚¤ì›Œë“œ'}, height=500)
            fig_bar.update_layout(yaxis={'categoryorder': 'total ascending'})
            fig_bar.update_traces(marker_color='#418cdc' )
            st.plotly_chart(fig_bar, use_container_width=True)
            with st.expander("ë°ì´í„° í…Œì´ë¸” ë³´ê¸°"):
                st.dataframe(top_20_keywords.reset_index(name='ë¹ˆë„ìˆ˜').rename(columns={'index': 'í‚¤ì›Œë“œ'}), use_container_width=True)
        with col2:
            wordcloud_data = keyword_counts.to_dict()
            wc = WordCloud(width=200, height=200, scale=15, background_color='white', colormap='viridis', max_words=200, relative_scaling=0.3).generate_from_frequencies(wordcloud_data)
            st.image(wc.to_array())

        st.markdown("---")
        st.markdown("##### **1-2. ì „ì²´ í‚¤ì›Œë“œ ì—°ë„ë³„ íŠ¸ë Œë“œ**")
        df_trend_global = df.dropna(subset=[keyword_col, 'publication_year']).copy()
        df_trend_global['publication_year'] = pd.to_numeric(df_trend_global['publication_year'], errors='coerce').dropna().astype(int)
        df_trend_global['keywords'] = df_trend_global[keyword_col].str.split(';').apply(lambda x: [kw.split('(')[0].strip() for kw in x if kw.strip()])
        df_trend_global = df_trend_global.explode('keywords')
        df_trend_global = df_trend_global[df_trend_global['keywords'] != '']
        top_10_global_keywords = keyword_counts.nlargest(10).index.tolist()
        trend_data_global = df_trend_global[df_trend_global['keywords'].isin(top_10_global_keywords)]
        trend_counts_global = trend_data_global.groupby(['publication_year', 'keywords']).size().unstack(fill_value=0)
        for kw in top_10_global_keywords:
            if kw not in trend_counts_global.columns:
                trend_counts_global[kw] = 0
        trend_counts_global = trend_counts_global[top_10_global_keywords]

        fig_stream_global = px.bar(trend_counts_global, x=trend_counts_global.index, y=trend_counts_global.columns, title="<b>ì „ì²´ ë°ì´í„°ì˜ ì—°ë„ë³„ í•µì‹¬ í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ë³€í™”</b>", labels={'publication_year': 'ë°œí–‰ì—°ë„', 'value': 'í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜', 'variable': 'í‚¤ì›Œë“œ'}, category_orders={"variable": top_10_global_keywords})
        fig_stream_global.update_layout(barmode='stack', legend_title_text='Top 10 í‚¤ì›Œë“œ')
        st.plotly_chart(fig_stream_global, use_container_width=True)
        with st.expander("ì—°ë„ë³„ ë¹ˆë„ìˆ˜ ë°ì´í„° ë³´ê¸°"):
            st.dataframe(trend_counts_global.sort_index(ascending=False), use_container_width=True)

        st.markdown("---")
        st.subheader("2. ì£¼ìš” êµ­ê°€ë³„ í‚¤ì›Œë“œ ë¶„ì„")
        country_col = 'First_Author_Country'
        if country_col in df.columns:
            country_series = df.dropna(subset=[country_col])[country_col].str.split(';').explode().str.strip()
            top_countries = country_series[country_series != ''].value_counts().nlargest(20).index.tolist()
            selected_country = st.selectbox("ë¶„ì„í•  êµ­ê°€ë¥¼ ì„ íƒí•˜ì„¸ìš”:", options=top_countries, key='deepdive_country_selector')

            if selected_country:
                country_df = df[df[country_col].str.contains(re.escape(selected_country), na=False)].copy()
                st.markdown(f"##### **2-1. {selected_country}ì˜ í•µì‹¬ í‚¤ì›Œë“œ ë¹ˆë„**")
                country_keywords_series = country_df.dropna(subset=[keyword_col])[keyword_col]
                country_all_keywords_raw = country_keywords_series.str.split(';').explode()
                country_pure_keywords = country_all_keywords_raw.str.split('(').str[0].str.strip()
                country_pure_keywords = country_pure_keywords[country_pure_keywords[country_pure_keywords != ''].notna()]

                if not country_pure_keywords.empty:
                    country_keyword_counts = country_pure_keywords.value_counts()
                    c_col1, c_col2 = st.columns([1, 1])
                    with c_col1:
                        c_top_20 = country_keyword_counts.nlargest(20)
                        c_fig_bar = px.bar(c_top_20, x=c_top_20.values, y=c_top_20.index, orientation='h', labels={'x': 'ë¹ˆë„ìˆ˜', 'y': 'í‚¤ì›Œë“œ'}, height=500)
                        c_fig_bar.update_layout(yaxis={'categoryorder': 'total ascending'})
                        c_fig_bar.update_traces(marker_color='#418cdc' )
                        st.plotly_chart(c_fig_bar, use_container_width=True)
                        with st.expander(f"{selected_country} í‚¤ì›Œë“œ ë°ì´í„° ë³´ê¸°"):
                            st.dataframe(c_top_20.reset_index(name='ë¹ˆë„ìˆ˜').rename(columns={'index': 'í‚¤ì›Œë“œ'}), use_container_width=True)
                    with c_col2:
                        c_wc_data = country_keyword_counts.to_dict()
                        c_wc = WordCloud(width=200, height=200, scale=15, background_color='white', colormap='cividis', max_words=200, relative_scaling=0.3).generate_from_frequencies(c_wc_data)
                        st.image(c_wc.to_array())
                else:
                    st.warning(f"'{selected_country}'ì— ëŒ€í•œ í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

                st.markdown(f"##### **2-2. {selected_country}ì˜ ì—°ë„ë³„ í‚¤ì›Œë“œ íŠ¸ë Œë“œ**")
                country_df_trend = country_df.dropna(subset=[keyword_col, 'publication_year']).copy()
                country_df_trend['publication_year'] = pd.to_numeric(country_df_trend['publication_year'], errors='coerce').dropna().astype(int)
                country_df_trend['keywords'] = country_df_trend[keyword_col].str.split(';').apply(lambda x: [kw.split('(')[0].strip() for kw in x if kw.strip()])
                country_df_trend = country_df_trend.explode('keywords')
                country_df_trend = country_df_trend[country_df_trend['keywords'] != '']
                country_trend_data = country_df_trend[country_df_trend['keywords'].isin(top_10_global_keywords)]
                country_trend_counts = country_trend_data.groupby(['publication_year', 'keywords']).size().unstack(fill_value=0)
                for kw in top_10_global_keywords:
                    if kw not in country_trend_counts.columns:
                        country_trend_counts[kw] = 0
                country_trend_counts = country_trend_counts[top_10_global_keywords]

                if not country_trend_counts.empty:
                    country_fig_stream = px.bar(country_trend_counts, x=country_trend_counts.index, y=country_trend_counts.columns, title=f"<b>{selected_country}ì˜ ì—°ë„ë³„ í•µì‹¬ í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜ ë³€í™” (Global Top 10 ê¸°ì¤€)</b>", labels={'publication_year': 'ë°œí–‰ì—°ë„', 'value': 'í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜', 'variable': 'í‚¤ì›Œë“œ'}, category_orders={"variable": top_10_global_keywords})
                    country_fig_stream.update_layout(barmode='stack', legend_title_text='Top 10 í‚¤ì›Œë“œ')
                    st.plotly_chart(country_fig_stream, use_container_width=True)
                    with st.expander("ì—°ë„ë³„ ë¹ˆë„ìˆ˜ ë°ì´í„° ë³´ê¸°"):
                        st.dataframe(country_trend_counts.sort_index(ascending=False), use_container_width=True)
                else:
                    st.warning(f"{selected_country}ì—ì„œ ê¸€ë¡œë²Œ Top 10 í‚¤ì›Œë“œì— ëŒ€í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ íŠ¸ë Œë“œë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning(f"'{country_col}' ì»¬ëŸ¼ì´ ì—†ì–´ êµ­ê°€ë³„ ë¶„ì„ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")
        st.subheader("3. íŠ¹ì • ê¸°ìˆ ì˜ ê¸€ë¡œë²Œ ë¦¬ë” ì¶”ì ")
        institution_col = 'All_Institutions'
        if institution_col in df.columns:
            selected_keyword_for_inst = st.selectbox("ë¶„ì„í•  í•µì‹¬ ê¸°ìˆ (í‚¤ì›Œë“œ)ì„ ì„ íƒí•˜ì„¸ìš”:", options=keyword_counts.nlargest(50).index, key="inst_keyword_select")
            if selected_keyword_for_inst:
                keyword_df = df[df[keyword_col].str.contains(re.escape(selected_keyword_for_inst), na=False)].copy()
                inst_series = keyword_df.dropna(subset=[institution_col])[institution_col].str.split(';').explode().str.strip()
                non_blank_inst = inst_series[inst_series != '']
                if not non_blank_inst.empty:
                    inst_counts = non_blank_inst.value_counts().nlargest(15)
                    fig_inst = px.bar(inst_counts, x=inst_counts.values, y=inst_counts.index, orientation='h', title=f"<b>'{selected_keyword_for_inst}' ê¸°ìˆ  ì„ ë„ ì—°êµ¬ê¸°ê´€ Top 15</b>", labels={'x': 'ë…¼ë¬¸ ìˆ˜', 'y': 'ì—°êµ¬ ê¸°ê´€'})
                    fig_inst.update_layout(yaxis={'categoryorder': 'total ascending'})
                    fig_inst.update_traces(marker_color='#418cdc' )
                    st.plotly_chart(fig_inst, use_container_width=True)
                    with st.expander("ë°ì´í„° í…Œì´ë¸” ë³´ê¸°"):
                        st.dataframe(inst_counts.reset_index(name='ë…¼ë¬¸ ìˆ˜').rename(columns={'index': 'ì—°êµ¬ ê¸°ê´€'}), use_container_width=True)
                else:
                    st.warning(f"'{selected_keyword_for_inst}' í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ë…¼ë¬¸ì˜ ê¸°ê´€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning(f"'{institution_col}' ì»¬ëŸ¼ì´ ì—†ì–´ ê¸°ê´€ ë¶„ì„ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    else:
        st.info("ì´ ëŒ€ì‹œë³´ë“œëŠ” 'ë¶„ì„ ëª¨ë“œ'ì—ì„œë§Œ í™œì„±í™”ë©ë‹ˆë‹¤. 'ê¸°ë³¸ ë™í–¥ ë¶„ì„' íƒ­ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")